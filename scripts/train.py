# è®­ç»ƒ U-Net æ¨¡å‹
# åœ¨ LoveDA è®­ç»ƒé›†ä¸Šè®­ç»ƒä¸€ä¸ª U-Net è¯­ä¹‰åˆ†å‰²æ¨¡å‹ï¼Œå¹¶åœ¨æ¯ä¸ª epoch åä¿å­˜æœ€æ–°æ¨¡å‹å‚æ•°

import os
import torch
import json
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

from datasets.loveda_dataset import SimpleLoveDADataset
from models.unet import UNet

# è®¡ç®— IoU
def compute_iou(pred, target, num_classes=8):
    ious = []
    pred_flat = pred.view(-1)
    target_flat = target.view(-1)
    
    for cls in range(1, num_classes):  # ä»1å¼€å§‹ï¼Œè·³è¿‡å¿½ç•¥åŒºåŸŸ
        pred_cls = pred_flat == cls
        target_cls = target_flat == cls
        
        intersection = (pred_cls & target_cls).sum().item()
        union = (pred_cls | target_cls).sum().item()
        
        if union > 0:
            ious.append(intersection / union)
    
    return np.mean(ious) if ious else 0.0

# è·å–é¡¹ç›®æ ¹ç›®å½•è·¯å¾„
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# ==================== æ–°å¢ï¼šæ”¹è¿›çš„æŸå¤±å‡½æ•° ====================
# å¼•å…¥ Focal Loss å’Œè¾¹ç•ŒæŸå¤±ä»¥æå‡æ¨¡å‹å¯¹éš¾åˆ†ç±»æ ·æœ¬å’Œè¾¹ç•ŒåŒºåŸŸçš„å…³æ³¨
def focal_loss(pred, target, alpha=0.25, gamma=2.0):
    ce_loss = F.cross_entropy(pred, target, reduction='none')
    pt = torch.exp(-ce_loss)
    focal_loss = alpha * (1-pt)**gamma * ce_loss
    return focal_loss.mean()

# è¾¹ç•ŒæŸå¤±ï¼Œå…³æ³¨ç±»åˆ«è¾¹ç•Œ
def boundary_loss(pred, target):

    # è®¡ç®—è¾¹ç•Œæƒé‡å›¾
    kernel = torch.ones(1, 1, 3, 3).to(pred.device)
    target_expanded = target.unsqueeze(1).float()
    
    # ä½¿ç”¨å·ç§¯æ£€æµ‹è¾¹ç•Œ
    smoothed = F.conv2d(target_expanded, kernel, padding=1)
    boundary = (smoothed > 0) & (smoothed < 9)  # è¾¹ç•Œåƒç´ 
    
    # åœ¨è¾¹ç•Œå¤„å¢åŠ æŸå¤±æƒé‡
    boundary_weight = boundary.float() * 3.0 + 1.0
    return (F.cross_entropy(pred, target, reduction='none') * boundary_weight.squeeze()).mean()

# ç»„åˆæŸå¤±å‡½æ•°
def compute_combined_loss(outputs, masks, class_weights, use_focal=True, use_boundary=True):

    # åŸºç¡€äº¤å‰ç†µæŸå¤±
    ce_loss = F.cross_entropy(outputs, masks, weight=class_weights)
    
    total_loss = ce_loss
    
    # å¯é€‰ï¼šæ·»åŠ Focal Loss
    if use_focal:
        focal = focal_loss(outputs, masks, alpha=0.25, gamma=2.0)
        total_loss = total_loss + 0.3 * focal
    
    # å¯é€‰ï¼šæ·»åŠ è¾¹ç•ŒæŸå¤±
    if use_boundary:
        boundary = boundary_loss(outputs, masks)
        total_loss = total_loss + 0.1 * boundary
    
    return total_loss

# Dice Loss
def dice_loss(pred, target, smooth=1e-6):

    pred = torch.softmax(pred, dim=1)
    num_classes = pred.shape[1]

    total_loss = 0
    for cls in range(num_classes):
        pred_cls = pred[:, cls]
        target_cls = (target == cls).float()
        
        intersection = (pred_cls * target_cls).sum()
        union = pred_cls.sum() + target_cls.sum()
        
        dice = (2. * intersection + smooth) / (union + smooth)
        total_loss += (1 - dice)
    
    return total_loss / num_classes

# åŸºäºçœŸå®æ ‡ç­¾åˆ†å¸ƒè®¡ç®—ç±»åˆ«æƒé‡
def compute_class_weights_from_distribution():
    distribution = {
        0: 0.0347,   # å¿½ç•¥åŒºåŸŸ - æƒé‡ä¸º0
        1: 0.4821,   # èƒŒæ™¯ - ä½æƒé‡
        2: 0.2346,   # å»ºç­‘ - ä¸­ç­‰æƒé‡
        3: 0.0825,   # é“è·¯ - è¾ƒé«˜æƒé‡
        4: 0.0378,   # æ°´ä½“ - é«˜æƒé‡
        5: 0.0656,   # è’åœ° - è¾ƒé«˜æƒé‡
        6: 0.0491,   # æ£®æ— - é«˜æƒé‡
        7: 0.0136    # å†œä¸š - æœ€é«˜æƒé‡
    }
    
    weights = torch.zeros(8)
    for cls, freq in distribution.items():
        if cls == 0:  # å¿½ç•¥åŒºåŸŸ
            weights[cls] = 0.0
        elif freq > 0:
            # ä½¿ç”¨é€†é¢‘ç‡åŠ æƒï¼Œæ›´å…³æ³¨ç¨€æœ‰ç±»åˆ«
            weights[cls] = 1.0 / (freq + 0.01)
        else:
            weights[cls] = 1.0
    
    # å½’ä¸€åŒ–ï¼ˆæ’é™¤ç±»åˆ«0ï¼‰
    weights[1:] = weights[1:] / weights[1:].sum() * 7
    
    return weights
# ==================== ç»“æŸï¼šæ”¹è¿›çš„æŸå¤±å‡½æ•° ====================

def main():
    # è®¾å¤‡é€‰æ‹©
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"è®¾å¤‡: {device}")

    # ==================== ä¼˜åŒ–åçš„è®­ç»ƒé…ç½® ====================
    config = dict(
        data_root='D:/Projects/SegmentationSystem/2021LoveDA',
        scene='both',
        target_size=256,
        train_samples=300,
        val_samples=60,
        batch_size=6,
        epochs=25,
        lr=2e-4,
        weight_decay=1e-4,
        early_stop_patience=10,
        
        # æ–°å¢ï¼šç±»åˆ«å¹³è¡¡ç­–ç•¥
        use_balanced_sampling=False,    # å¹³è¡¡é‡‡æ ·
        use_class_weights=True,        # ç±»åˆ«æƒé‡
        use_focal_loss=True,           # Focal Loss
        
        # æ•°æ®å¢å¼ºé…ç½®
        augment_config={
            'flip_prob': 0.3,
            'rotate_prob': 0.2,
            'color_jitter_prob': 0.1,
            'crop_prob': 0,
            'rare_class_aug_prob': 0,  # ç¨€æœ‰ç±»åˆ«å¢å¼ºæ¦‚ç‡
        },
        
        # æŸå¤±å‡½æ•°æƒé‡
        loss_weights={
            'ce': 1.0,      # äº¤å‰ç†µæŸå¤±æƒé‡
            'focal': 0.2,   # Focal Lossæƒé‡
            'boundary': 0.05, # è¾¹ç•ŒæŸå¤±æƒé‡
            'dice': 0.2     # Dice Lossæƒé‡
        },

        # CPUä¼˜åŒ–è®¾ç½®
        num_workers=0,          # Windowsä¸Šè®¾ä¸º0é¿å…é—®é¢˜
        pin_memory=False,
        
        # å†…å­˜ä¼˜åŒ–
        use_gradient_checkpointing=False,  # CPUä¸Šä¸éœ€è¦
        use_mixed_precision=False,         # CPUä¸Šä¸æ”¯æŒæ··åˆç²¾åº¦
    )
    # ==================== ç»“æŸï¼šè®­ç»ƒé…ç½® ====================

    # åŠ è½½è®­ç»ƒå’ŒéªŒè¯æ•°æ®é›†
    print("å‡†å¤‡æ•°æ®...")
    train_dataset = SimpleLoveDADataset(
        data_root=config['data_root'],
        mode='train',
        scene=config['scene'],
        target_size=config['target_size'],
        max_samples=config['train_samples'],
        augment=True,
        use_offline_resize=True
    )

    val_dataset = SimpleLoveDADataset(
        data_root=config['data_root'],
        mode='val',
        scene=config['scene'],
        target_size=config['target_size'],
        max_samples=config['val_samples'],
        augment=False,
        use_offline_resize=True
    )

    print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    print(f"éªŒè¯é›†å¤§å°: {len(val_dataset)}")

    # ==================== æ•°æ®åŠ è½½å™¨ï¼ˆæ”¯æŒå¹³è¡¡é‡‡æ ·ï¼‰ ====================
    if config.get('use_balanced_sampling', False):
        print("ä½¿ç”¨å¹³è¡¡é‡‡æ ·ç­–ç•¥...")
        # æ³¨æ„ï¼šéœ€è¦å…ˆåˆ›å»ºbalanced_sampler.pyæ–‡ä»¶
        try:
            from samplers.balanced_sampler import BalancedBatchSampler
            balanced_sampler = BalancedBatchSampler(train_dataset, batch_size=config['batch_size'])
            train_loader = DataLoader(
                train_dataset,
                batch_sampler=balanced_sampler,
                num_workers=0,
                pin_memory=False
            )
            print("å¹³è¡¡é‡‡æ ·å™¨åŠ è½½æˆåŠŸ")
        except ImportError:
            print("å¹³è¡¡é‡‡æ ·å™¨æœªæ‰¾åˆ°ï¼Œä½¿ç”¨æ™®é€šé‡‡æ ·")
            train_loader = DataLoader(
                train_dataset,
                batch_size=config['batch_size'],
                shuffle=True,
                num_workers=0,
                pin_memory=False
            )
    else:
        train_loader = DataLoader(
            train_dataset,
            batch_size=config['batch_size'],
            shuffle=True,
            num_workers=0,
            pin_memory=False
        )

    val_loader = DataLoader(
        val_dataset,
        batch_size=4,
        shuffle=False,
        num_workers=0,
        pin_memory=False
    )
    # ==================== ç»“æŸï¼šæ•°æ®åŠ è½½å™¨ ====================

    # æ¨¡å‹ä¸ä¼˜åŒ–å™¨
    print("åˆ›å»ºæ¨¡å‹...")
    model = UNet().to(device)

    # æ‰“å°æ¨¡å‹ä¿¡æ¯
    total_params = sum(p.numel() for p in model.parameters())
    print(f"æ¨¡å‹å‚æ•°é‡: {total_params:,}")

    # ä¼˜åŒ–å™¨
    optimizer = optim.AdamW(
        model.parameters(),
        lr=config['lr'],
        weight_decay=config['weight_decay']
    )

    # ==================== æŸå¤±å‡½æ•°è®¾ç½® ====================
    print("é…ç½®æŸå¤±å‡½æ•°...")
    
    # åŸºäºçœŸå®åˆ†å¸ƒè®¡ç®—ç±»åˆ«æƒé‡
    class_weights = compute_class_weights_from_distribution().to(device)
    print(f"åŸºäºåˆ†å¸ƒçš„ç±»åˆ«æƒé‡: {class_weights.cpu().numpy().round(3)}")
    print(f"ç±»åˆ«å«ä¹‰: 0=å¿½ç•¥, 1=èƒŒæ™¯, 2=å»ºç­‘, 3=é“è·¯, 4=æ°´ä½“, 5=è’åœ°, 6=æ£®æ—, 7=å†œä¸š")
    # ==================== ç»“æŸï¼šæŸå¤±å‡½æ•° ====================

    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer,
        mode='max',      # ç›‘æ§mIoUï¼Œè¦æœ€å¤§åŒ–
        factor=0.5,      # é™ä½å› å­
        patience=6,      # 6ä¸ªepochæ²¡æ”¹å–„å°±é™ä½
        min_lr=1e-6,
        verbose=True
    )

    # ä¿®æ”¹æ‰€æœ‰æ¨¡å‹ä¿å­˜è·¯å¾„
    model_dir = os.path.join(BASE_DIR, 'models')

    # è®­ç»ƒå‡†å¤‡
    os.makedirs(model_dir, exist_ok=True)
    os.makedirs(os.path.join(BASE_DIR, 'outputs'), exist_ok=True)

    # è®°å½•
    train_losses = []
    val_mious = []
    best_miou = 0
    best_epoch = 0
    no_improve_count = 0
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M')
    output_dir = os.path.join(BASE_DIR, 'outputs', f'training_{timestamp}')
    os.makedirs(output_dir, exist_ok=True)

    # ä¿å­˜é…ç½®
    with open(os.path.join(output_dir, 'config.json'), 'w') as f:
        json.dump(config, f, indent=2)

    print(f"\nå¼€å§‹è®­ç»ƒ ({config['epochs']}ä¸ªepoch)...")
    print("=" * 80)

    # è®­ç»ƒå¾ªç¯
    for epoch in range(config['epochs']):
        # ==================== è®­ç»ƒé˜¶æ®µ ====================
        model.train()
        epoch_train_loss = 0
        batch_count = 0

        for batch_idx, (images, masks) in enumerate(train_loader):
            images, masks = images.to(device), masks.to(device)
            
            # å‰å‘ä¼ æ’­
            outputs = model(images)
            
            # è®¡ç®—ç»„åˆæŸå¤±
            loss = compute_combined_loss(
                outputs, masks, class_weights,
                use_focal=config.get('use_focal_loss', True),
                use_boundary=True
            )
            
            # å¯é€‰ï¼šæ·»åŠ Dice Loss
            if config['loss_weights'].get('dice', 0) > 0:
                loss = loss + config['loss_weights']['dice'] * dice_loss(outputs, masks)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            
            # æ¢¯åº¦è£å‰ª
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            optimizer.step()
            
            epoch_train_loss += loss.item()
            batch_count += 1
            
            # æ¯å‡ ä¸ªbatchæ‰“å°ä¸€æ¬¡
            if (batch_idx + 1) % max(1, len(train_loader) // 4) == 0:
                with torch.no_grad():
                    preds = torch.argmax(outputs, dim=1)
                    batch_iou = compute_iou(preds[0], masks[0])
                    
                    # è®¡ç®—ç±»åˆ«åˆ†å¸ƒ
                    unique_classes = torch.unique(masks[0])
                    
                    print(f"Epoch {epoch+1:02d} | Batch {batch_idx+1:03d}/{len(train_loader)} | "
                          f"Loss: {loss.item():.4f} | Batch IoU: {batch_iou:.4f} | "
                          f"ç±»åˆ«: {sorted(unique_classes.tolist())}")
        # ==================== ç»“æŸï¼šè®­ç»ƒé˜¶æ®µ ====================

        avg_train_loss = epoch_train_loss / batch_count
        train_losses.append(avg_train_loss)

        # ==================== éªŒè¯é˜¶æ®µ ====================
        model.eval()
        epoch_val_miou = 0
        sample_count = 0
        
        # å„ç±»åˆ«IoUç»Ÿè®¡
        class_iou_sum = torch.zeros(8, device=device)
        class_count = torch.zeros(8, device=device)
        
        with torch.no_grad():
            for val_images, val_masks in val_loader:
                val_images, val_masks = val_images.to(device), val_masks.to(device)
                val_outputs = model(val_images)
                val_preds = torch.argmax(val_outputs, dim=1)
                
                # è®¡ç®—æ¯ä¸ªæ ·æœ¬çš„IoU
                for i in range(val_preds.shape[0]):
                    sample_iou = compute_iou(val_preds[i], val_masks[i])
                    epoch_val_miou += sample_iou
                    
                    # ç»Ÿè®¡å„ç±»åˆ«IoU
                    for cls in range(8):
                        if cls > 0:  # è·³è¿‡å¿½ç•¥åŒºåŸŸ
                            pred_cls = val_preds[i] == cls
                            mask_cls = val_masks[i] == cls
                            
                            intersection = (pred_cls & mask_cls).sum().item()
                            union = (pred_cls | mask_cls).sum().item()
                            
                            if union > 0:
                                class_iou_sum[cls] += intersection / union
                                class_count[cls] += 1
                
                sample_count += val_preds.shape[0]
        
        avg_val_miou = epoch_val_miou / sample_count
        val_mious.append(avg_val_miou)
        
        # è®¡ç®—å„ç±»åˆ«å¹³å‡IoU
        avg_class_iou = []
        for cls in range(1, 8):  # è·³è¿‡å¿½ç•¥åŒºåŸŸ
            if class_count[cls] > 0:
                avg_class_iou.append((cls, class_iou_sum[cls].item() / class_count[cls].item()))
        # ==================== ç»“æŸï¼šéªŒè¯é˜¶æ®µ ====================

        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step(avg_val_miou)
        current_lr = optimizer.param_groups[0]['lr']

        # æ‰“å°ç»“æœ
        print(f"\n{'='*60}")
        print(f"Epoch {epoch+1:02d}/{config['epochs']} ç»“æœ:")
        print(f"{'-'*60}")
        print(f"  è®­ç»ƒæŸå¤±: {avg_train_loss:.4f}")
        print(f"  éªŒè¯mIoU: {avg_val_miou:.4f} ({avg_val_miou*100:.1f}%)")
        print(f"  å­¦ä¹ ç‡: {current_lr:.2e}")
        
        # æ˜¾ç¤ºå„ç±»åˆ«æ€§èƒ½
        if avg_class_iou:
            print(f"\n  å„ç±»åˆ«IoU (å‰3):")
            avg_class_iou.sort(key=lambda x: x[1], reverse=True)
            for cls, iou in avg_class_iou[:3]:
                class_names = ['å¿½ç•¥', 'èƒŒæ™¯', 'å»ºç­‘', 'é“è·¯', 'æ°´ä½“', 'è’åœ°', 'æ£®æ—', 'å†œä¸š']
                print(f"    {class_names[cls]}({cls}): {iou:.4f}")

        # æ˜¾ç¤ºè¿›æ­¥
        if epoch > 0:
            improvement = avg_val_miou - val_mious[-2]
            if improvement > 0:
                print(f"  â†‘ mIoUæå‡: +{improvement:.4f}")
            else:
                print(f"  â†“ mIoUä¸‹é™: {improvement:.4f}")

        # ==================== æ¨¡å‹ä¿å­˜ ====================
        best_model_path = os.path.join(model_dir, 'unet_best.pth')
        if avg_val_miou > best_miou:
            best_miou = avg_val_miou
            best_epoch = epoch + 1
            no_improve_count = 0
            
            # ä¿å­˜å®Œæ•´æ£€æŸ¥ç‚¹
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_miou': best_miou,
                'train_loss': avg_train_loss,
                'config': config,
                'class_weights': class_weights,
                'class_iou': avg_class_iou,
            }, best_model_path)
            
            print(f"ä¿å­˜æœ€ä½³æ¨¡å‹ï¼mIoU: {best_miou:.4f}")
        else:
            no_improve_count += 1
            print(f"{no_improve_count}ä¸ªepochæœªæå‡")
        
        # ä¿å­˜æœ€æ–°æ¨¡å‹
        latest_model_path = os.path.join(model_dir, 'unet_latest.pth')
        torch.save(model.state_dict(), latest_model_path)

        # æ—©åœæ£€æŸ¥
        if no_improve_count >= config['early_stop_patience']:
            print(f"\næ—©åœè§¦å‘: {no_improve_count}ä¸ªepochæœªæå‡")
            print(f"   æœ€ä½³mIoU: {best_miou:.4f} (Epoch {best_epoch})")
            break

        # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
        checkpoint_path = os.path.join(model_dir, f'unet_epoch{epoch+1}.pth')
        if (epoch + 1) % 10 == 0:
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'train_loss': avg_train_loss,
                'val_miou': avg_val_miou,
            }, checkpoint_path)
            print(f"  ğŸ“ ä¿å­˜æ£€æŸ¥ç‚¹: epoch {epoch+1}")
        
        print(f"{'='*60}\n")

    # ==================== è®­ç»ƒå®Œæˆ ====================
    print("\nè®­ç»ƒå®Œæˆ!")
    print(f"æœ€ä½³æ¨¡å‹åœ¨ Epoch {best_epoch}, mIoU: {best_miou:.4f} ({best_miou*100:.1f}%)")

    # ç»˜åˆ¶è®­ç»ƒæ›²çº¿
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
        
    ax1.plot(train_losses, marker='o', linewidth=2, markersize=4)
    ax1.set_title('Training Loss', fontsize=14, fontweight='bold')
    ax1.set_xlabel('Epoch', fontsize=12)
    ax1.set_ylabel('Loss', fontsize=12)
    ax1.grid(True, alpha=0.3)
    ax1.legend(['Loss'], loc='upper right')
        
    ax2.plot(val_mious, marker='s', color='orange', linewidth=2, markersize=4)
    ax2.axhline(y=best_miou, color='r', linestyle='--', linewidth=2, 
                label=f'Best: {best_miou:.3f}')
    ax2.set_title('Validation mIoU', fontsize=14, fontweight='bold')
    ax2.set_xlabel('Epoch', fontsize=12)
    ax2.set_ylabel('mIoU', fontsize=12)
    ax2.grid(True, alpha=0.3)
    ax2.legend(loc='lower right')
        
    plt.tight_layout()
    plt.savefig(f'{output_dir}/training_curves.png', dpi=120, bbox_inches='tight')
    plt.close()
        
    # ä¿å­˜è®­ç»ƒç»Ÿè®¡
    stats = {
        'best_miou': float(best_miou),
        'best_epoch': best_epoch,
        'final_train_loss': float(train_losses[-1]),
        'final_val_miou': float(val_mious[-1]),
        'total_epochs_trained': len(train_losses),
        'config': config,
        'class_weights': class_weights.cpu().tolist(),
    }
        
    with open(f'{output_dir}/training_stats.json', 'w') as f:
        json.dump(stats, f, indent=2)
        
    print(f"\nè®­ç»ƒç»Ÿè®¡:")
    print(f"  å¼€å§‹mIoU: {val_mious[0]:.4f} ({val_mious[0]*100:.1f}%)")
    print(f"  ç»“æŸmIoU: {val_mious[-1]:.4f} ({val_mious[-1]*100:.1f}%)")
    print(f"  æ€»æå‡: {(val_mious[-1] - val_mious[0]):.4f} ({(val_mious[-1] - val_mious[0])*100:.1f}%)")
    
    if best_miou >= 0.25:
        print(f"\nè‰¯å¥½æˆç»©ï¼mIoU: {best_miou:.4f} ({best_miou*100:.1f}%)")
    elif best_miou >= 0.20:
        print(f"\nä¸­ç­‰æˆç»©ï¼Œè¿˜æœ‰æå‡ç©ºé—´: {best_miou:.4f} ({best_miou*100:.1f}%)")
    else:
        print(f"\néœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ï¼Œå½“å‰mIoU: {best_miou:.4f} ({best_miou*100:.1f}%)")
        
    print(f"\nè®­ç»ƒç»“æœä¿å­˜åœ¨: {output_dir}")
    print(f"æœ€ä½³æ¨¡å‹: {best_model_path}")
    print(f"æœ€æ–°æ¨¡å‹: {latest_model_path}")
    print(f"\n{'='*80}")

if __name__ == '__main__':
    main()